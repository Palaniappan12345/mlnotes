<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Palaniappan</title>
    <link>https://Palaniappan12345.github.io/mlnotes/</link>
    <description>Recent content on Palaniappan</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 07 Sep 2020 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://Palaniappan12345.github.io/mlnotes/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Dimensionality-Reduction-Algorithms</title>
      <link>https://Palaniappan12345.github.io/mlnotes/python/ml_algorithms/dimensionality_reduction_algorithms/</link>
      <pubDate>Mon, 07 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://Palaniappan12345.github.io/mlnotes/python/ml_algorithms/dimensionality_reduction_algorithms/</guid>
      <description># importing required libraries import pandas as pd from sklearn.decomposition import PCA from sklearn.linear_model import LinearRegression from sklearn.metrics import mean_squared_error from sklearn.metrics import accuracy_score# read the train and test dataset train_data = pd.read_csv(&amp;#39;train.csv&amp;#39;) test_data = pd.read_csv(&amp;#39;test.csv&amp;#39;) # view the top 3 rows of the dataset print(train_data.head(3))  Item_Weight Item_Visibility Item_MRP Outlet_Establishment_Year \ 0 6.800000 0.037490 48.6034 2004 1 15.600000 0.172597 114.8518 1997 2 12.911575 0.054721 107.8254 1985 Item_Outlet_Sales Item_Fat_Content_LF Item_Fat_Content_Low Fat \ 0 291.</description>
    </item>
    
    <item>
      <title>Gradient-Boosting-Algorithms</title>
      <link>https://Palaniappan12345.github.io/mlnotes/python/ml_algorithms/gradient_boosting_algorithms/</link>
      <pubDate>Mon, 07 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://Palaniappan12345.github.io/mlnotes/python/ml_algorithms/gradient_boosting_algorithms/</guid>
      <description># importing required libraries import pandas as pd from sklearn.ensemble import GradientBoostingClassifier from sklearn.metrics import accuracy_score# read the train and test dataset train_data = pd.read_csv(&amp;#39;train-data.csv&amp;#39;) test_data = pd.read_csv(&amp;#39;test-data.csv&amp;#39;) # shape of the dataset print(&amp;#39;Shape of training data :&amp;#39;,train_data.shape) print(&amp;#39;Shape of testing data :&amp;#39;,test_data.shape) Shape of training data : (712, 25) Shape of testing data : (179, 25)  train_x = train_data.drop(columns=[&amp;#39;Survived&amp;#39;],axis=1) train_y = train_data[&amp;#39;Survived&amp;#39;] # seperate the independent and target variable on testing data test_x = test_data.</description>
    </item>
    
    <item>
      <title>K-means</title>
      <link>https://Palaniappan12345.github.io/mlnotes/python/ml_algorithms/k-means/</link>
      <pubDate>Mon, 07 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://Palaniappan12345.github.io/mlnotes/python/ml_algorithms/k-means/</guid>
      <description># importing required libraries import pandas as pd from sklearn.tree import DecisionTreeClassifier from sklearn.cluster import KMeans from sklearn.metrics import accuracy_score# read the train and test dataset train_data = pd.read_csv(&amp;#39;train1-data.csv&amp;#39;) test_data = pd.read_csv(&amp;#39;test1-data.csv&amp;#39;) # shape of the dataset print(&amp;#39;Shape of training data :&amp;#39;,train_data.shape) print(&amp;#39;Shape of testing data :&amp;#39;,test_data.shape) Shape of training data : (100, 5) Shape of testing data : (100, 5)  model = KMeans() # fit the model with the training data model.</description>
    </item>
    
    <item>
      <title>XGBoost</title>
      <link>https://Palaniappan12345.github.io/mlnotes/python/ml_algorithms/xgboost/</link>
      <pubDate>Mon, 07 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://Palaniappan12345.github.io/mlnotes/python/ml_algorithms/xgboost/</guid>
      <description># importing required libraries import pandas as pd from sklearn.ensemble import GradientBoostingClassifier from xgboost import XGBClassifier from sklearn.metrics import accuracy_score# read the train and test dataset train_data = pd.read_csv(&amp;#39;train-data.csv&amp;#39;) test_data = pd.read_csv(&amp;#39;test-data.csv&amp;#39;) # shape of the dataset print(&amp;#39;Shape of training data :&amp;#39;,train_data.shape) print(&amp;#39;Shape of testing data :&amp;#39;,test_data.shape) Shape of training data : (712, 25) Shape of testing data : (179, 25)  train_x = train_data.drop(columns=[&amp;#39;Survived&amp;#39;],axis=1) train_y = train_data[&amp;#39;Survived&amp;#39;] # seperate the independent and target variable on testing data test_x = test_data.</description>
    </item>
    
    <item>
      <title>3D-Surface</title>
      <link>https://Palaniappan12345.github.io/mlnotes/python/data_visualisation/3d_surface/</link>
      <pubDate>Sat, 05 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://Palaniappan12345.github.io/mlnotes/python/data_visualisation/3d_surface/</guid>
      <description>from mpl_toolkits.mplot3d import Axes3D # noqa: F401 unused import import matplotlib.pyplot as plt from matplotlib import cm from matplotlib.ticker import LinearLocator, FormatStrFormatter import numpy as npfig = plt.figure() ax = fig.gca(projection=&amp;#39;3d&amp;#39;) # Make data. X = np.arange(-5, 5, 0.25) Y = np.arange(-5, 5, 0.25) X, Y = np.meshgrid(X, Y) R = np.sqrt(X**2 + Y**2) Z = np.sin(R) # Plot the surface. surf = ax.plot_surface(X, Y, Z, cmap=cm.coolwarm, linewidth=0, antialiased=False) # Customize the z axis.</description>
    </item>
    
    <item>
      <title>Decision-Tree-Classifier</title>
      <link>https://Palaniappan12345.github.io/mlnotes/python/ml_algorithms/decision-tree-classifier/</link>
      <pubDate>Sat, 05 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://Palaniappan12345.github.io/mlnotes/python/ml_algorithms/decision-tree-classifier/</guid>
      <description># importing required libraries import pandas as pd from sklearn.tree import DecisionTreeClassifier from sklearn.metrics import accuracy_score# read the train and test dataset train_data = pd.read_csv(&amp;#39;train-data.csv&amp;#39;) test_data = pd.read_csv(&amp;#39;test-data.csv&amp;#39;) # shape of the dataset print(&amp;#39;Shape of training data :&amp;#39;,train_data.shape) print(&amp;#39;Shape of testing data :&amp;#39;,test_data.shape) Shape of training data : (712, 25) Shape of testing data : (179, 25)  train_x = train_data.drop(columns=[&amp;#39;Survived&amp;#39;],axis=1) train_y = train_data[&amp;#39;Survived&amp;#39;] # seperate the independent and target variable on testing data test_x = test_data.</description>
    </item>
    
    <item>
      <title>Ellipse-plot</title>
      <link>https://Palaniappan12345.github.io/mlnotes/python/data_visualisation/ellipse-plot/</link>
      <pubDate>Sat, 05 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://Palaniappan12345.github.io/mlnotes/python/data_visualisation/ellipse-plot/</guid>
      <description>import matplotlib.pyplot as plt import numpy as np from matplotlib.patches import EllipseNUM = 250 ells = [Ellipse(xy=np.random.rand(2) * 10, width=np.random.rand(), height=np.random.rand(), angle=np.random.rand() * 360) for i in range(NUM)] fig, ax = plt.subplots(subplot_kw={&amp;#39;aspect&amp;#39;: &amp;#39;equal&amp;#39;}) for e in ells: ax.add_artist(e) e.set_clip_box(ax.bbox) e.set_alpha(np.random.rand()) e.set_facecolor(np.random.rand(3)) ax.set_xlim(0, 10) ax.set_ylim(0, 10) plt.show() </description>
    </item>
    
    <item>
      <title>Filled-Polygon</title>
      <link>https://Palaniappan12345.github.io/mlnotes/python/data_visualisation/filled-polygon/</link>
      <pubDate>Sat, 05 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://Palaniappan12345.github.io/mlnotes/python/data_visualisation/filled-polygon/</guid>
      <description>from mpl_toolkits.mplot3d import Axes3D # noqa: F401 unused import import matplotlib.pyplot as plt from matplotlib import cm from matplotlib.ticker import LinearLocator, FormatStrFormatter import numpy as npdef koch_snowflake(order, scale=10): &amp;#34;&amp;#34;&amp;#34; Return two lists x, y of point coordinates of the Koch snowflake. Arguments --------- order : int The recursion depth. scale : float The extent of the snowflake (edge length of the base triangle). &amp;#34;&amp;#34;&amp;#34; def _koch_snowflake_complex(order): if order == 0: # initial triangle angles = np.</description>
    </item>
    
    <item>
      <title>Linear-Regression</title>
      <link>https://Palaniappan12345.github.io/mlnotes/python/ml_algorithms/linear_regression/</link>
      <pubDate>Sat, 05 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://Palaniappan12345.github.io/mlnotes/python/ml_algorithms/linear_regression/</guid>
      <description># importing required libraries import pandas as pd from sklearn.linear_model import LinearRegression from sklearn.metrics import mean_squared_error# read the train and test dataset train_data = pd.read_csv(&amp;#39;train.csv&amp;#39;) test_data = pd.read_csv(&amp;#39;test.csv&amp;#39;) print(train_data.head())  Item_Weight Item_Visibility Item_MRP Outlet_Establishment_Year \ 0 6.800000 0.037490 48.6034 2004 1 15.600000 0.172597 114.8518 1997 2 12.911575 0.054721 107.8254 1985 3 11.800000 0.098312 81.4618 1998 4 17.850000 0.046600 125.1388 2004 Item_Outlet_Sales Item_Fat_Content_LF Item_Fat_Content_Low Fat \ 0 291.6204 0 1 1 2163.</description>
    </item>
    
    <item>
      <title>Logistic-Regression</title>
      <link>https://Palaniappan12345.github.io/mlnotes/python/ml_algorithms/logistic-regression/</link>
      <pubDate>Sat, 05 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://Palaniappan12345.github.io/mlnotes/python/ml_algorithms/logistic-regression/</guid>
      <description># importing required libraries import pandas as pd from sklearn.linear_model import LogisticRegression from sklearn.metrics import accuracy_score# read the train and test dataset train_data = pd.read_csv(&amp;#39;train-data.csv&amp;#39;) test_data = pd.read_csv(&amp;#39;test-data.csv&amp;#39;) print(train_data.head())  Survived Age Fare Pclass_1 Pclass_2 Pclass_3 Sex_female \ 0 0 28.500000 7.2292 0 0 1 0 1 1 27.000000 10.5000 0 1 0 1 2 1 29.699118 16.1000 0 0 1 1 3 0 29.699118 0.0000 1 0 0 0 4 0 17.</description>
    </item>
    
    <item>
      <title>Naive-Bayes-Classifier</title>
      <link>https://Palaniappan12345.github.io/mlnotes/python/ml_algorithms/naive-bayes-classifier/</link>
      <pubDate>Sat, 05 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://Palaniappan12345.github.io/mlnotes/python/ml_algorithms/naive-bayes-classifier/</guid>
      <description># importing required libraries import pandas as pd from sklearn.linear_model import LogisticRegression from sklearn.naive_bayes import GaussianNB from sklearn.metrics import accuracy_score# read the train and test dataset train_data = pd.read_csv(&amp;#39;train-data.csv&amp;#39;) test_data = pd.read_csv(&amp;#39;test-data.csv&amp;#39;) print(train_data.head())  Survived Age Fare Pclass_1 Pclass_2 Pclass_3 Sex_female \ 0 0 28.500000 7.2292 0 0 1 0 1 1 27.000000 10.5000 0 1 0 1 2 1 29.699118 16.1000 0 0 1 1 3 0 29.699118 0.0000 1 0 0 0 4 0 17.</description>
    </item>
    
    <item>
      <title>Path-plot</title>
      <link>https://Palaniappan12345.github.io/mlnotes/python/data_visualisation/path-plot/</link>
      <pubDate>Sat, 05 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://Palaniappan12345.github.io/mlnotes/python/data_visualisation/path-plot/</guid>
      <description>import matplotlib.path as mpath import matplotlib.patches as mpatches import matplotlib.pyplot as plt fig, ax = plt.subplots() Path = mpath.Path path_data = [ (Path.MOVETO, (1.58, -2.57)), (Path.CURVE4, (0.35, -1.1)), (Path.CURVE4, (-1.75, 2.0)), (Path.CURVE4, (0.375, 2.0)), (Path.LINETO, (0.85, 1.15)), (Path.CURVE4, (2.2, 3.2)), (Path.CURVE4, (3, 0.05)), (Path.CURVE4, (2.0, -0.5)), (Path.CLOSEPOLY, (1.58, -2.57)), ] codes, verts = zip(*path_data) path = mpath.Path(verts, codes) patch = mpatches.PathPatch(path, facecolor=&amp;#39;r&amp;#39;, alpha=0.5) ax.add_patch(patch) # plot control points and connecting lines x, y = zip(*path.</description>
    </item>
    
    <item>
      <title>Pcolormesh-plots</title>
      <link>https://Palaniappan12345.github.io/mlnotes/python/data_visualisation/pcolormesh-plots/</link>
      <pubDate>Sat, 05 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://Palaniappan12345.github.io/mlnotes/python/data_visualisation/pcolormesh-plots/</guid>
      <description>import matplotlib import matplotlib.pyplot as plt from matplotlib.colors import BoundaryNorm from matplotlib.ticker import MaxNLocator import numpy as np# make these smaller to increase the resolution dx, dy = 0.05, 0.05 # generate 2 2d grids for the x &amp;amp; y bounds y, x = np.mgrid[slice(1, 5 + dy, dy), slice(1, 5 + dx, dx)] z = np.sin(x)**10 + np.cos(10 + y*x) * np.cos(x) # x and y are bounds, so z should be the value *inside* those bounds.</description>
    </item>
    
    <item>
      <title>Polar-plot</title>
      <link>https://Palaniappan12345.github.io/mlnotes/python/data_visualisation/polar-plot/</link>
      <pubDate>Sat, 05 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://Palaniappan12345.github.io/mlnotes/python/data_visualisation/polar-plot/</guid>
      <description>from mpl_toolkits.mplot3d import Axes3D # noqa: F401 unused import import matplotlib.pyplot as plt from matplotlib import cm from matplotlib.ticker import LinearLocator, FormatStrFormatter import numpy as npr = np.arange(0, 2, 0.01) theta = 2 * np.pi * r ax = plt.subplot(111, projection=&amp;#39;polar&amp;#39;) ax.plot(theta, r) ax.set_rmax(2) ax.set_rticks([0.5, 1, 1.5, 2]) # Less radial ticks ax.set_rlabel_position(-22.5) # Move radial labels away from plotted line ax.grid(True) ax.set_title(&amp;#34;A line plot on a polar axis&amp;#34;, va=&amp;#39;bottom&amp;#39;) plt.</description>
    </item>
    
    <item>
      <title>Random-Forest-Classifier</title>
      <link>https://Palaniappan12345.github.io/mlnotes/python/ml_algorithms/random-forest-classifier/</link>
      <pubDate>Sat, 05 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://Palaniappan12345.github.io/mlnotes/python/ml_algorithms/random-forest-classifier/</guid>
      <description># importing required libraries import pandas as pd from sklearn.ensemble import RandomForestClassifier from sklearn.metrics import accuracy_score# read the train and test dataset train_data = pd.read_csv(&amp;#39;train-data.csv&amp;#39;) test_data = pd.read_csv(&amp;#39;test-data.csv&amp;#39;)# view the top 3 rows of the dataset print(train_data.head(3)) # shape of the dataset print(&amp;#39;\nShape of training data :&amp;#39;,train_data.shape) print(&amp;#39;\nShape of testing data :&amp;#39;,test_data.shape)  Survived Age Fare Pclass_1 Pclass_2 Pclass_3 Sex_female \ 0 0 28.500000 7.2292 0 0 1 0 1 1 27.</description>
    </item>
    
    <item>
      <title>Simple-plot</title>
      <link>https://Palaniappan12345.github.io/mlnotes/python/data_visualisation/simple-plot/</link>
      <pubDate>Sat, 05 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://Palaniappan12345.github.io/mlnotes/python/data_visualisation/simple-plot/</guid>
      <description>import matplotlib import matplotlib.pyplot as plt import numpy as np# Data for plotting t = np.arange(0.0, 2.0, 0.01) s = 1 + np.sin(2 * np.pi * t) fig, ax = plt.subplots() ax.plot(t, s) [&amp;lt;matplotlib.lines.Line2D at 0x7fcfbdfa4400&amp;gt;]  ax.set(xlabel=&amp;#39;time (s)&amp;#39;, ylabel=&amp;#39;voltage (mV)&amp;#39;, title=&amp;#39;About as simple as it gets, folks&amp;#39;) print(ax.grid()) None  fig.savefig(&amp;#34;test.png&amp;#34;) print(plt.show()) None  </description>
    </item>
    
    <item>
      <title>Sub-plots</title>
      <link>https://Palaniappan12345.github.io/mlnotes/python/data_visualisation/sub-plots/</link>
      <pubDate>Sat, 05 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://Palaniappan12345.github.io/mlnotes/python/data_visualisation/sub-plots/</guid>
      <description>import matplotlib import matplotlib.pyplot as plt import numpy as npx1 = np.linspace(0.0, 5.0) x2 = np.linspace(0.0, 2.0) y1 = np.cos(2 * np.pi * x1) * np.exp(-x1) y2 = np.cos(2 * np.pi * x2) plt.subplot(2, 1, 1) plt.plot(x1, y1, &amp;#39;o-&amp;#39;) plt.title(&amp;#39;A tale of 2 subplots&amp;#39;) plt.ylabel(&amp;#39;Damped oscillation&amp;#39;) Text(0, 0.5, &#39;Damped oscillation&#39;)  plt.subplot(2, 1, 2) plt.plot(x2, y2, &amp;#39;.-&amp;#39;) plt.xlabel(&amp;#39;time (s)&amp;#39;) plt.ylabel(&amp;#39;Undamped&amp;#39;) plt.show() </description>
    </item>
    
    <item>
      <title>Support-Vector-Machine</title>
      <link>https://Palaniappan12345.github.io/mlnotes/python/ml_algorithms/support-vector-machine/</link>
      <pubDate>Sat, 05 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://Palaniappan12345.github.io/mlnotes/python/ml_algorithms/support-vector-machine/</guid>
      <description># importing required libraries import pandas as pd from sklearn.svm import SVC from sklearn.metrics import accuracy_score# read the train and test dataset train_data = pd.read_csv(&amp;#39;train-data.csv&amp;#39;) test_data = pd.read_csv(&amp;#39;test-data.csv&amp;#39;) # shape of the dataset print(&amp;#39;Shape of training data :&amp;#39;,train_data.shape) print(&amp;#39;Shape of testing data :&amp;#39;,test_data.shape) Shape of training data : (712, 25) Shape of testing data : (179, 25)  train_x = train_data.drop(columns=[&amp;#39;Survived&amp;#39;],axis=1) train_y = train_data[&amp;#39;Survived&amp;#39;] # seperate the independent and target variable on testing data test_x = test_data.</description>
    </item>
    
    <item>
      <title>kNN-algorithm</title>
      <link>https://Palaniappan12345.github.io/mlnotes/python/ml_algorithms/knn-algorithm/</link>
      <pubDate>Sat, 05 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://Palaniappan12345.github.io/mlnotes/python/ml_algorithms/knn-algorithm/</guid>
      <description># importing required libraries import pandas as pd from sklearn.neighbors import KNeighborsClassifier from sklearn.metrics import accuracy_score# read the train and test dataset train_data = pd.read_csv(&amp;#39;train-data.csv&amp;#39;) test_data = pd.read_csv(&amp;#39;test-data.csv&amp;#39;) print(train_data.head())  Survived Age Fare Pclass_1 Pclass_2 Pclass_3 Sex_female \ 0 0 28.500000 7.2292 0 0 1 0 1 1 27.000000 10.5000 0 1 0 1 2 1 29.699118 16.1000 0 0 1 1 3 0 29.699118 0.0000 1 0 0 0 4 0 17.</description>
    </item>
    
    <item>
      <title>Axes-Metrics</title>
      <link>https://Palaniappan12345.github.io/mlnotes/python/numpy/axes_metrics/</link>
      <pubDate>Fri, 04 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://Palaniappan12345.github.io/mlnotes/python/numpy/axes_metrics/</guid>
      <description>import math import statistics import numpy as np import scipy.stats import pandas as pda = np.array([[1, 1, 1], [2, 3, 1], [4, 9, 2], [8, 27, 4], [16, 1, 1]]) a array([[ 1, 1, 1], [ 2, 3, 1], [ 4, 9, 2], [ 8, 27, 4], [16, 1, 1]])  np.mean(a) 5.4  a.mean() 5.4  np.median(a) 2.0  a.var(ddof=1) 53.40000000000001  np.mean(a, axis=0) array([6.2, 8.2, 1.8])  a.mean(axis=0) array([6.</description>
    </item>
    
    <item>
      <title>Bar-chart</title>
      <link>https://Palaniappan12345.github.io/mlnotes/python/data_visualisation/bar_chart/</link>
      <pubDate>Fri, 04 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://Palaniappan12345.github.io/mlnotes/python/data_visualisation/bar_chart/</guid>
      <description>import math import statistics import numpy as np import scipy.stats import pandas as pdimport matplotlib.pyplot as plt plt.style.use(&amp;#39;ggplot&amp;#39;)x = np.arange(21) y = np.random.randint(21, size=21) err = np.random.randn(21)fig, ax = plt.subplots() ax.bar(x, y, yerr=err) ax.set_xlabel(&amp;#39;x&amp;#39;) ax.set_ylabel(&amp;#39;y&amp;#39;) plt.show() </description>
    </item>
    
    <item>
      <title>Basic-Linear-Regression</title>
      <link>https://Palaniappan12345.github.io/mlnotes/python/sklearn/basic-linear-regression/</link>
      <pubDate>Fri, 04 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://Palaniappan12345.github.io/mlnotes/python/sklearn/basic-linear-regression/</guid>
      <description>import matplotlib.pyplot as plt import numpy as np from sklearn import datasets, linear_model from sklearn.metrics import mean_squared_error, r2_score import pandas as pd# Load the diabetes dataset diabetes_data = datasets.load_diabetes() # Print all keys and number of raw and columns print(diabetes_data.keys, diabetes_data.data.shape) &amp;lt;built-in method keys of Bunch object at 0x7f1448121c20&amp;gt; (442, 10)  print(diabetes_data.feature_names) [&#39;age&#39;, &#39;sex&#39;, &#39;bmi&#39;, &#39;bp&#39;, &#39;s1&#39;, &#39;s2&#39;, &#39;s3&#39;, &#39;s4&#39;, &#39;s5&#39;, &#39;s6&#39;]  df = pd.DataFrame(diabetes_data.data) df.columns = diabetes_data.feature_names df[&amp;#39;target&amp;#39;] = diabetes_data.</description>
    </item>
    
    <item>
      <title>Basic-PCA</title>
      <link>https://Palaniappan12345.github.io/mlnotes/python/sklearn/basic_pca/</link>
      <pubDate>Fri, 04 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://Palaniappan12345.github.io/mlnotes/python/sklearn/basic_pca/</guid>
      <description>from sklearn.pipeline import Pipeline, FeatureUnion from sklearn.model_selection import GridSearchCV from sklearn.svm import SVC from sklearn.datasets import load_iris from sklearn.decomposition import PCA from sklearn.feature_selection import SelectKBestiris = load_iris()X, y = iris.data, iris.targetpca = PCA(n_components=2)# Maybe some original features where good, too? selection = SelectKBest(k=1) # Build estimator from PCA and Univariate selection: combined_features = FeatureUnion([(&amp;#34;pca&amp;#34;, pca), (&amp;#34;univ_select&amp;#34;, selection)]) # Use combined features to transform dataset: X_features = combined_features.fit(X, y).transform(X) svm = SVC(kernel=&amp;#34;linear&amp;#34;)pipeline = Pipeline([(&amp;#34;features&amp;#34;, combined_features), (&amp;#34;svm&amp;#34;, svm)]) param_grid = dict(features__pca__n_components=[1, 2, 3], features__univ_select__k=[1, 2], svm__C=[0.</description>
    </item>
    
    <item>
      <title>Basic-tokenisation</title>
      <link>https://Palaniappan12345.github.io/mlnotes/python/sklearn/basic_tokenisation/</link>
      <pubDate>Fri, 04 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://Palaniappan12345.github.io/mlnotes/python/sklearn/basic_tokenisation/</guid>
      <description>import math import statistics import numpy as np import scipy.stats import pandas as pd import sklearn import reSms_content=[&amp;#39;What is going on&amp;#39;,&amp;#39;How is your life&amp;#39;,&amp;#39;oh! god what is happening&amp;#39;] df=pd.DataFrame(Sms_content,columns={&amp;#39;sms&amp;#39;}) df  .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }    sms     0 What is going on   1 How is your life   2 oh!</description>
    </item>
    
    <item>
      <title>Box-plot</title>
      <link>https://Palaniappan12345.github.io/mlnotes/python/data_visualisation/box-plot/</link>
      <pubDate>Fri, 04 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://Palaniappan12345.github.io/mlnotes/python/data_visualisation/box-plot/</guid>
      <description>import math import statistics import numpy as np import scipy.stats import pandas as pdimport matplotlib.pyplot as plt plt.style.use(&amp;#39;ggplot&amp;#39;)np.random.seed(seed=0) x = np.random.randn(1000) y = np.random.randn(100) z = np.random.randn(10)fig, ax = plt.subplots() ax.boxplot((x, y, z), vert=False, showmeans=True, meanline=True, labels=(&amp;#39;x&amp;#39;, &amp;#39;y&amp;#39;, &amp;#39;z&amp;#39;), patch_artist=True, medianprops={&amp;#39;linewidth&amp;#39;: 2, &amp;#39;color&amp;#39;: &amp;#39;purple&amp;#39;}, meanprops={&amp;#39;linewidth&amp;#39;: 2, &amp;#39;color&amp;#39;: &amp;#39;red&amp;#39;}) plt.show() </description>
    </item>
    
    <item>
      <title>Confusion-matrix</title>
      <link>https://Palaniappan12345.github.io/mlnotes/python/sklearn/confusion_matrix/</link>
      <pubDate>Fri, 04 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://Palaniappan12345.github.io/mlnotes/python/sklearn/confusion_matrix/</guid>
      <description>import math import statistics import numpy as np import scipy.stats import pandas as pd import sklearnfrom sklearn.metrics import confusion_matrixdata = {&amp;#39;y_Actual&amp;#39;: [1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0], &amp;#39;y_Predicted&amp;#39;: [1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0] }df = pd.DataFrame(data, columns=[&amp;#39;y_Actual&amp;#39;,&amp;#39;y_Predicted&amp;#39;])f1_score(true, pred,average=&amp;#34;micro&amp;#34;) 0.3333333333333333  confusion_matrix = pd.crosstab(df[&amp;#39;y_Actual&amp;#39;], df[&amp;#39;y_Predicted&amp;#39;], rownames=[&amp;#39;Actual&amp;#39;], colnames=[&amp;#39;Predicted&amp;#39;]) print (confusion_matrix) Predicted 0 1 Actual 0 5 2 1 1 4  </description>
    </item>
    
    <item>
      <title>Correlation-Coefficient-Metrics</title>
      <link>https://Palaniappan12345.github.io/mlnotes/python/numpy/correlation_coefficient_metrics/</link>
      <pubDate>Fri, 04 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://Palaniappan12345.github.io/mlnotes/python/numpy/correlation_coefficient_metrics/</guid>
      <description>import math import statistics import numpy as np import scipy.stats import pandas as pdx = [8.0, 1, 2.5, 4, 28.0] x_with_nan = [8.0, 1, 2.5, math.nan, 4, 28.0] x [8.0, 1, 2.5, 4, 28.0]  y, y_with_nan = np.array(x), np.array(x_with_nan) z, z_with_nan = pd.Series(x), pd.Series(x_with_nan) y array([ 8. , 1. , 2.5, 4. , 28. ])  x = list(range(-10, 11)) y = [0, 2, 2, 2, 2, 3, 3, 6, 7, 4, 7, 6, 6, 9, 4, 5, 5, 10, 11, 12, 14] x_, y_ = np.</description>
    </item>
    
    <item>
      <title>Correlation-Metrics</title>
      <link>https://Palaniappan12345.github.io/mlnotes/python/numpy/correlation_metrics/</link>
      <pubDate>Fri, 04 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://Palaniappan12345.github.io/mlnotes/python/numpy/correlation_metrics/</guid>
      <description>import math import statistics import numpy as np import scipy.stats import pandas as pdx = [8.0, 1, 2.5, 4, 28.0] x_with_nan = [8.0, 1, 2.5, math.nan, 4, 28.0] x [8.0, 1, 2.5, 4, 28.0]  y, y_with_nan = np.array(x), np.array(x_with_nan) z, z_with_nan = pd.Series(x), pd.Series(x_with_nan) y array([ 8. , 1. , 2.5, 4. , 28. ])  x = list(range(-10, 11)) y = [0, 2, 2, 2, 2, 3, 3, 6, 7, 4, 7, 6, 6, 9, 4, 5, 5, 10, 11, 12, 14] x_, y_ = np.</description>
    </item>
    
    <item>
      <title>Data-importing-and-exploring</title>
      <link>https://Palaniappan12345.github.io/mlnotes/python/sklearn/basic_data_importing_and_exploration/</link>
      <pubDate>Fri, 04 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://Palaniappan12345.github.io/mlnotes/python/sklearn/basic_data_importing_and_exploration/</guid>
      <description>import math import statistics import numpy as np import scipy.stats import pandas as pd import sklearndf = pd.read_csv(&amp;#39;glass.csv&amp;#39;)df  .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }    RI Na Mg Al Si K Ca Ba Fe Type     0 1.52101 13.64 4.49 1.10 71.78 0.06 8.75 0.00 0.0 1   1 1.</description>
    </item>
    
    <item>
      <title>Data-visualisation-using-dataset</title>
      <link>https://Palaniappan12345.github.io/mlnotes/python/sklearn/basic_data_visualisation/</link>
      <pubDate>Fri, 04 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://Palaniappan12345.github.io/mlnotes/python/sklearn/basic_data_visualisation/</guid>
      <description>import math import statistics import numpy as np import scipy.stats import pandas as pd import sklearndf = pd.read_csv(&amp;#39;glass.csv&amp;#39;)df  .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }    RI Na Mg Al Si K Ca Ba Fe Type     0 1.52101 13.64 4.49 1.10 71.78 0.06 8.75 0.00 0.0 1   1 1.</description>
    </item>
    
    <item>
      <title>DataFrames</title>
      <link>https://Palaniappan12345.github.io/mlnotes/python/pandas/dataframes/</link>
      <pubDate>Fri, 04 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://Palaniappan12345.github.io/mlnotes/python/pandas/dataframes/</guid>
      <description>import numpy as np import scipy.stats import pandas as pd import sklearndict = {&amp;#34;country&amp;#34;: [&amp;#34;Brazil&amp;#34;, &amp;#34;Russia&amp;#34;, &amp;#34;India&amp;#34;, &amp;#34;China&amp;#34;, &amp;#34;South Africa&amp;#34;], &amp;#34;capital&amp;#34;: [&amp;#34;Brasilia&amp;#34;, &amp;#34;Moscow&amp;#34;, &amp;#34;New Dehli&amp;#34;, &amp;#34;Beijing&amp;#34;, &amp;#34;Pretoria&amp;#34;], &amp;#34;area&amp;#34;: [8.516, 17.10, 3.286, 9.597, 1.221], &amp;#34;population&amp;#34;: [200.4, 143.5, 1252, 1357, 52.98] }df = pd.DataFrame(dict)df  .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }    country capital area population     0 Brazil Brasilia 8.</description>
    </item>
    
    <item>
      <title>Dataframe</title>
      <link>https://Palaniappan12345.github.io/mlnotes/python/numpy/dataframe/</link>
      <pubDate>Fri, 04 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://Palaniappan12345.github.io/mlnotes/python/numpy/dataframe/</guid>
      <description>import math import statistics import numpy as np import scipy.stats import pandas as pda=( [ [2, 3, 1], [4, 9, 2], [8, 27, 4], [16, 1, 1]]) a [[2, 3, 1], [4, 9, 2], [8, 27, 4], [16, 1, 1]]  row_names = [&amp;#39;first&amp;#39;, &amp;#39;second&amp;#39;, &amp;#39;third&amp;#39;, &amp;#39;fourth&amp;#39;] col_names = [&amp;#39;A&amp;#39;, &amp;#39;B&amp;#39;, &amp;#39;C&amp;#39;] df = pd.DataFrame( a,index=row_names, columns=col_names) df  .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .</description>
    </item>
    
    <item>
      <title>F1-score</title>
      <link>https://Palaniappan12345.github.io/mlnotes/python/sklearn/f1_score/</link>
      <pubDate>Fri, 04 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://Palaniappan12345.github.io/mlnotes/python/sklearn/f1_score/</guid>
      <description>import math import statistics import numpy as np import scipy.stats import pandas as pd import sklearnfrom sklearn.metrics import f1_score true = [0, 1, 2, 0, 1, 2] pred = [0, 2, 1, 0, 0, 1]f1_score(true, pred,average=None).mean() 0.26666666666666666  f1_score(true, pred,average=&amp;#34;macro&amp;#34;) 0.26666666666666666  f1_score(true, pred,average=&amp;#34;micro&amp;#34;) 0.3333333333333333  f1_score(true, pred,average=&amp;#34;weighted&amp;#34;) 0.26666666666666666  </description>
    </item>
    
    <item>
      <title>Geometric-Mean-Metrics</title>
      <link>https://Palaniappan12345.github.io/mlnotes/python/numpy/geometric_mean_metrics/</link>
      <pubDate>Fri, 04 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://Palaniappan12345.github.io/mlnotes/python/numpy/geometric_mean_metrics/</guid>
      <description>import math import statistics import numpy as np import scipy.stats import pandas as pdx = [8.0, 1, 2.5, 4, 28.0] x_with_nan = [8.0, 1, 2.5, math.nan, 4, 28.0] x [8.0, 1, 2.5, 4, 28.0]  y, y_with_nan = np.array(x), np.array(x_with_nan) z, z_with_nan = pd.Series(x), pd.Series(x_with_nan) y array([ 8. , 1. , 2.5, 4. , 28. ])  gmean = 1 for item in x: gmean *= itemgmean **= 1 / len(x) gmean 4.</description>
    </item>
    
    <item>
      <title>Heatmap</title>
      <link>https://Palaniappan12345.github.io/mlnotes/python/data_visualisation/heatmap/</link>
      <pubDate>Fri, 04 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://Palaniappan12345.github.io/mlnotes/python/data_visualisation/heatmap/</guid>
      <description>import math import statistics import numpy as np import scipy.stats import pandas as pdimport matplotlib.pyplot as plt plt.style.use(&amp;#39;ggplot&amp;#39;)x = np.arange(21) y = 5 + 2 * x + 2 * np.random.randn(21) slope, intercept, r, *__ = scipy.stats.linregress(x, y) line = f&amp;#39;Regression line: y={intercept:.2f}+{slope:.2f}x, r={r:.2f}&amp;#39;matrix = np.cov(x, y).round(decimals=2) fig, ax = plt.subplots() ax.imshow(matrix) ax.grid(False) ax.xaxis.set(ticks=(0, 1), ticklabels=(&amp;#39;x&amp;#39;, &amp;#39;y&amp;#39;)) ax.yaxis.set(ticks=(0, 1), ticklabels=(&amp;#39;x&amp;#39;, &amp;#39;y&amp;#39;)) ax.set_ylim(1.5, -0.5) for i in range(2): for j in range(2): ax.</description>
    </item>
    
    <item>
      <title>Histogram</title>
      <link>https://Palaniappan12345.github.io/mlnotes/python/data_visualisation/histogram/</link>
      <pubDate>Fri, 04 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://Palaniappan12345.github.io/mlnotes/python/data_visualisation/histogram/</guid>
      <description>import math import statistics import numpy as np import scipy.stats import pandas as pdimport matplotlib.pyplot as plt plt.style.use(&amp;#39;ggplot&amp;#39;)np.random.seed(seed=0) x = np.random.randn(1000) y = np.random.randn(100) z = np.random.randn(10)hist, bin_edges = np.histogram(x, bins=10) hist array([ 9, 20, 70, 146, 217, 239, 160, 86, 38, 15])  bin_edges array([-3.04614305, -2.46559324, -1.88504342, -1.3044936 , -0.72394379, -0.14339397, 0.43715585, 1.01770566, 1.59825548, 2.1788053 , 2.75935511])  fig, ax = plt.subplots() ax.hist(x, bin_edges, cumulative=False) ax.set_xlabel(&amp;#39;x&amp;#39;) ax.set_ylabel(&amp;#39;Frequency&amp;#39;) plt.show() fig, ax = plt.</description>
    </item>
    
    <item>
      <title>Indexing-DataFrames</title>
      <link>https://Palaniappan12345.github.io/mlnotes/python/pandas/indexing_dataframes/</link>
      <pubDate>Fri, 04 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://Palaniappan12345.github.io/mlnotes/python/pandas/indexing_dataframes/</guid>
      <description>import numpy as np import scipy.stats import pandas as pd import sklearndict = {&amp;#34;country&amp;#34;: [&amp;#34;Brazil&amp;#34;, &amp;#34;Russia&amp;#34;, &amp;#34;India&amp;#34;, &amp;#34;China&amp;#34;, &amp;#34;South Africa&amp;#34;], &amp;#34;capital&amp;#34;: [&amp;#34;Brasilia&amp;#34;, &amp;#34;Moscow&amp;#34;, &amp;#34;New Dehli&amp;#34;, &amp;#34;Beijing&amp;#34;, &amp;#34;Pretoria&amp;#34;], &amp;#34;area&amp;#34;: [8.516, 17.10, 3.286, 9.597, 1.221], &amp;#34;population&amp;#34;: [200.4, 143.5, 1252, 1357, 52.98] }df = pd.DataFrame(dict)df  .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }    country capital area population     0 Brazil Brasilia 8.</description>
    </item>
    
    <item>
      <title>K-Neighbors-Classifier</title>
      <link>https://Palaniappan12345.github.io/mlnotes/python/sklearn/k-neighbors_classifier/</link>
      <pubDate>Fri, 04 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://Palaniappan12345.github.io/mlnotes/python/sklearn/k-neighbors_classifier/</guid>
      <description>import math import statistics import numpy as np import scipy.stats import pandas as pd import sklearn from sklearn.naive_bayes import GaussianNB from sklearn.metrics import accuracy_score from sklearn.model_selection import train_test_splitdf = pd.read_csv(&amp;#39;glass.csv&amp;#39;)df  .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }    RI Na Mg Al Si K Ca Ba Fe Type     0 1.</description>
    </item>
    
    <item>
      <title>Label-encoding</title>
      <link>https://Palaniappan12345.github.io/mlnotes/python/sklearn/label_encoding/</link>
      <pubDate>Fri, 04 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://Palaniappan12345.github.io/mlnotes/python/sklearn/label_encoding/</guid>
      <description>import numpy as np import scipy.stats import pandas as pd import sklearndata = pd.read_csv(&amp;#34;grocery.csv&amp;#34;) print(data)   Item Price 0 Onion 100 1 Egg 10 2 Tomato 60 3 Carrot 60 4 Cabbage 20 5 Milk 30 6 Potato 50 7 Mosquito Bat 200 8 Scissor 75 9 Shampoo 3  # label encoding the data  from sklearn.preprocessing import LabelEncoder le = LabelEncoder() data[&amp;#39;Item&amp;#39;]= le.fit_transform(data[&amp;#39;Item&amp;#39;]) print(data)  Item Price 0 5 100 1 2 10 2 9 60 3 1 60 4 0 20 5 3 30 6 6 50 7 4 200 8 7 75 9 8 3  </description>
    </item>
    
    <item>
      <title>Linear-SVC</title>
      <link>https://Palaniappan12345.github.io/mlnotes/python/sklearn/linear_svc/</link>
      <pubDate>Fri, 04 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://Palaniappan12345.github.io/mlnotes/python/sklearn/linear_svc/</guid>
      <description>import math import statistics import numpy as np import scipy.stats import pandas as pd import sklearn from sklearn.naive_bayes import GaussianNB from sklearn.metrics import accuracy_score from sklearn.model_selection import train_test_splitdf = pd.read_csv(&amp;#39;glass.csv&amp;#39;)df  .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }    RI Na Mg Al Si K Ca Ba Fe Type     0 1.</description>
    </item>
    
    <item>
      <title>Mean-Metrics</title>
      <link>https://Palaniappan12345.github.io/mlnotes/python/numpy/mean_metrics/</link>
      <pubDate>Fri, 04 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://Palaniappan12345.github.io/mlnotes/python/numpy/mean_metrics/</guid>
      <description>import math import statistics import numpy as np import scipy.stats import pandas as pdx = [8.0, 1, 2.5, 4, 28.0] x_with_nan = [8.0, 1, 2.5, math.nan, 4, 28.0] x [8.0, 1, 2.5, 4, 28.0]  x_with_nan [8.0, 1, 2.5, nan, 4, 28.0]  y, y_with_nan = np.array(x), np.array(x_with_nan) z, z_with_nan = pd.Series(x), pd.Series(x_with_nan) y array([ 8. , 1. , 2.5, 4. , 28. ])  y_with_nan z 0 8.0 1 1.</description>
    </item>
    
    <item>
      <title>Median-Metrics</title>
      <link>https://Palaniappan12345.github.io/mlnotes/python/numpy/median_metrics/</link>
      <pubDate>Fri, 04 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://Palaniappan12345.github.io/mlnotes/python/numpy/median_metrics/</guid>
      <description>import math import statistics import numpy as np import scipy.stats import pandas as pdx = [8.0, 1, 2.5, 4, 28.0] x_with_nan = [8.0, 1, 2.5, math.nan, 4, 28.0] x [8.0, 1, 2.5, 4, 28.0]  y, y_with_nan = np.array(x), np.array(x_with_nan) z, z_with_nan = pd.Series(x), pd.Series(x_with_nan) y array([ 8. , 1. , 2.5, 4. , 28. ])  n = len(x) if n % 2: median_ = sorted(x)[round(0.5*(n-1))] else: x_ord, index = sorted(x), round(0.</description>
    </item>
    
    <item>
      <title>Mode-Metrics</title>
      <link>https://Palaniappan12345.github.io/mlnotes/python/numpy/mode_metrics/</link>
      <pubDate>Fri, 04 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://Palaniappan12345.github.io/mlnotes/python/numpy/mode_metrics/</guid>
      <description>import math import statistics import numpy as np import scipy.stats import pandas as pdx = [8.0, 1, 2.5, 4, 28.0] x_with_nan = [8.0, 1, 2.5, math.nan, 4, 28.0] x [8.0, 1, 2.5, 4, 28.0]  y, y_with_nan = np.array(x), np.array(x_with_nan) z, z_with_nan = pd.Series(x), pd.Series(x_with_nan) y array([ 8. , 1. , 2.5, 4. , 28. ])  u = [2, 3, 2, 8, 12] mode_ = max((u.count(item), item) for item in set(u))[1] mode_ 2  mode_ = statistics.</description>
    </item>
    
    <item>
      <title>One-hot-encoding</title>
      <link>https://Palaniappan12345.github.io/mlnotes/python/sklearn/one-hot-encoding/</link>
      <pubDate>Fri, 04 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://Palaniappan12345.github.io/mlnotes/python/sklearn/one-hot-encoding/</guid>
      <description>import numpy as np import scipy.stats import pandas as pd import sklearndata = pd.read_csv(&amp;#34;grocery.csv&amp;#34;) print(data)   Item Price 0 Onion 100 1 Egg 10 2 Tomato 60 3 Carrot 60 4 Cabbage 20 5 Milk 30 6 Potato 50 7 Mosquito Bat 200 8 Scissor 75 9 Shampoo 3  # label encoding the data  from sklearn.preprocessing import LabelEncoder le = LabelEncoder() data[&amp;#39;Item&amp;#39;]= le.fit_transform(data[&amp;#39;Item&amp;#39;]) print(data)  Item Price 0 5 100 1 2 10 2 9 60 3 1 60 4 0 20 5 3 30 6 6 50 7 4 200 8 7 75 9 8 3  # importing one hot encoder from sklearn  from sklearn.</description>
    </item>
    
    <item>
      <title>Pandas-Aggregations</title>
      <link>https://Palaniappan12345.github.io/mlnotes/python/pandas/pandas-aggregations/</link>
      <pubDate>Fri, 04 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://Palaniappan12345.github.io/mlnotes/python/pandas/pandas-aggregations/</guid>
      <description>import numpy as np import scipy.stats import pandas as pd import sklearn#Applying Aggregations on DataFrame df = pd.DataFrame(np.random.randn(10, 4), index = pd.date_range(&amp;#39;1/1/2000&amp;#39;, periods=10), columns = [&amp;#39;A&amp;#39;, &amp;#39;B&amp;#39;, &amp;#39;C&amp;#39;, &amp;#39;D&amp;#39;]) df  .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }    A B C D     2000-01-01 0.744195 0.496521 -0.134224 -0.409785   2000-01-02 -0.</description>
    </item>
    
    <item>
      <title>Pandas-Categorial-Data</title>
      <link>https://Palaniappan12345.github.io/mlnotes/python/pandas/pandas-categorial-data/</link>
      <pubDate>Fri, 04 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://Palaniappan12345.github.io/mlnotes/python/pandas/pandas-categorial-data/</guid>
      <description>import numpy as np import scipy.stats import pandas as pd import sklearn#Object Creation s = pd.Series([&amp;#34;a&amp;#34;,&amp;#34;b&amp;#34;,&amp;#34;c&amp;#34;,&amp;#34;a&amp;#34;], dtype=&amp;#34;category&amp;#34;) s 0 a 1 b 2 c 3 a dtype: category Categories (3, object): [&#39;a&#39;, &#39;b&#39;, &#39;c&#39;]  cat = pd.Categorical([&amp;#39;a&amp;#39;, &amp;#39;b&amp;#39;, &amp;#39;c&amp;#39;, &amp;#39;a&amp;#39;, &amp;#39;b&amp;#39;, &amp;#39;c&amp;#39;]) cat [&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;a&#39;, &#39;b&#39;, &#39;c&#39;] Categories (3, object): [&#39;a&#39;, &#39;b&#39;, &#39;c&#39;]  cat = pd.Categorical([&amp;#34;a&amp;#34;, &amp;#34;c&amp;#34;, &amp;#34;c&amp;#34;, np.nan], categories=[&amp;#34;b&amp;#34;, &amp;#34;a&amp;#34;, &amp;#34;c&amp;#34;]) df = pd.DataFrame({&amp;#34;cat&amp;#34;:cat, &amp;#34;s&amp;#34;:[&amp;#34;a&amp;#34;, &amp;#34;c&amp;#34;, &amp;#34;c&amp;#34;, np.</description>
    </item>
    
    <item>
      <title>Pandas-Concatenation</title>
      <link>https://Palaniappan12345.github.io/mlnotes/python/pandas/pandas-concatenation/</link>
      <pubDate>Fri, 04 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://Palaniappan12345.github.io/mlnotes/python/pandas/pandas-concatenation/</guid>
      <description>import numpy as np import scipy.stats import pandas as pd import sklearnone = pd.DataFrame({ &amp;#39;Name&amp;#39;: [&amp;#39;Alex&amp;#39;, &amp;#39;Amy&amp;#39;, &amp;#39;Allen&amp;#39;, &amp;#39;Alice&amp;#39;, &amp;#39;Ayoung&amp;#39;], &amp;#39;subject_id&amp;#39;:[&amp;#39;sub1&amp;#39;,&amp;#39;sub2&amp;#39;,&amp;#39;sub4&amp;#39;,&amp;#39;sub6&amp;#39;,&amp;#39;sub5&amp;#39;], &amp;#39;Marks_scored&amp;#39;:[98,90,87,69,78]}, index=[1,2,3,4,5]) two = pd.DataFrame({ &amp;#39;Name&amp;#39;: [&amp;#39;Billy&amp;#39;, &amp;#39;Brian&amp;#39;, &amp;#39;Bran&amp;#39;, &amp;#39;Bryce&amp;#39;, &amp;#39;Betty&amp;#39;], &amp;#39;subject_id&amp;#39;:[&amp;#39;sub2&amp;#39;,&amp;#39;sub4&amp;#39;,&amp;#39;sub3&amp;#39;,&amp;#39;sub6&amp;#39;,&amp;#39;sub5&amp;#39;], &amp;#39;Marks_scored&amp;#39;:[89,80,79,97,88]}, index=[1,2,3,4,5]) pd.concat([one,two])  .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }    Name subject_id Marks_scored     1 Alex sub1 98   2 Amy sub2 90   3 Allen sub4 87   4 Alice sub6 69   5 Ayoung sub5 78   1 Billy sub2 89   2 Brian sub4 80   3 Bran sub3 79   4 Bryce sub6 97   5 Betty sub5 88     pd.</description>
    </item>
    
    <item>
      <title>Pandas-Data-Functionality</title>
      <link>https://Palaniappan12345.github.io/mlnotes/python/pandas/pandas-data-functionality/</link>
      <pubDate>Fri, 04 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://Palaniappan12345.github.io/mlnotes/python/pandas/pandas-data-functionality/</guid>
      <description>import numpy as np import scipy.stats import pandas as pd import sklearn#Create a Range of Dates pd.date_range(&amp;#39;1/1/2011&amp;#39;, periods=5) DatetimeIndex([&#39;2011-01-01&#39;, &#39;2011-01-02&#39;, &#39;2011-01-03&#39;, &#39;2011-01-04&#39;, &#39;2011-01-05&#39;], dtype=&#39;datetime64[ns]&#39;, freq=&#39;D&#39;)  #Change the Date Frequency pd.date_range(&amp;#39;1/1/2011&amp;#39;, periods=5,freq=&amp;#39;M&amp;#39;) DatetimeIndex([&#39;2011-01-31&#39;, &#39;2011-02-28&#39;, &#39;2011-03-31&#39;, &#39;2011-04-30&#39;, &#39;2011-05-31&#39;], dtype=&#39;datetime64[ns]&#39;, freq=&#39;M&#39;)  #bdate_range pd.date_range(&amp;#39;1/1/2011&amp;#39;, periods=5) DatetimeIndex([&#39;2011-01-01&#39;, &#39;2011-01-02&#39;, &#39;2011-01-03&#39;, &#39;2011-01-04&#39;, &#39;2011-01-05&#39;], dtype=&#39;datetime64[ns]&#39;, freq=&#39;D&#39;)  start = pd.datetime(2011, 1, 1) end = pd.datetime(2011, 1, 5) pd.date_range(start, end) &amp;lt;ipython-input-7-dd7f9190c50e&amp;gt;:1: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version.</description>
    </item>
    
    <item>
      <title>Pandas-Function-Application</title>
      <link>https://Palaniappan12345.github.io/mlnotes/python/pandas/pandas-function-application/</link>
      <pubDate>Fri, 04 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://Palaniappan12345.github.io/mlnotes/python/pandas/pandas-function-application/</guid>
      <description>import numpy as np import scipy.stats import pandas as pd import sklearn#Table-wise Function Application def adder(ele1,ele2): return ele1+ele2 df = pd.DataFrame(np.random.randn(5,3),columns=[&amp;#39;col1&amp;#39;,&amp;#39;col2&amp;#39;,&amp;#39;col3&amp;#39;]) df.pipe(adder,2) df.apply(np.mean) col1 -0.165957 col2 -0.488008 col3 -0.516572 dtype: float64  #Row or Column Wise Function Application df = pd.DataFrame(np.random.randn(5,3),columns=[&amp;#39;col1&amp;#39;,&amp;#39;col2&amp;#39;,&amp;#39;col3&amp;#39;]) df.apply(np.mean) df.apply(np.mean) col1 0.129294 col2 0.310800 col3 0.410874 dtype: float64  df = pd.DataFrame(np.random.randn(5,3),columns=[&amp;#39;col1&amp;#39;,&amp;#39;col2&amp;#39;,&amp;#39;col3&amp;#39;]) df.apply(lambda x: x.max() - x.min()) df.apply(np.mean) col1 0.284628 col2 -0.365105 col3 0.449976 dtype: float64  #Element Wise Function Application df = pd.</description>
    </item>
    
    <item>
      <title>Pandas-Iteration</title>
      <link>https://Palaniappan12345.github.io/mlnotes/python/pandas/pandas-iteration/</link>
      <pubDate>Fri, 04 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://Palaniappan12345.github.io/mlnotes/python/pandas/pandas-iteration/</guid>
      <description>import numpy as np import scipy.stats import pandas as pd import sklearnN=20 df = pd.DataFrame({ &amp;#39;A&amp;#39;: pd.date_range(start=&amp;#39;2016-01-01&amp;#39;,periods=N,freq=&amp;#39;D&amp;#39;), &amp;#39;x&amp;#39;: np.linspace(0,stop=N-1,num=N), &amp;#39;y&amp;#39;: np.random.rand(N), &amp;#39;C&amp;#39;: np.random.choice([&amp;#39;Low&amp;#39;,&amp;#39;Medium&amp;#39;,&amp;#39;High&amp;#39;],N).tolist(), &amp;#39;D&amp;#39;: np.random.normal(100, 10, size=(N)).tolist() }) for col in df: print(col) A x y C D  #iteritems() df = pd.DataFrame(np.random.randn(4,3),columns=[&amp;#39;col1&amp;#39;,&amp;#39;col2&amp;#39;,&amp;#39;col3&amp;#39;]) for key,value in df.iteritems(): print (key,value) col1 0 1.383371 1 -0.752669 2 -0.989764 3 0.184005 Name: col1, dtype: float64 col2 0 -1.432349 1 1.804341 2 1.730258 3 -0.</description>
    </item>
    
    <item>
      <title>Pandas-Merging/Joining</title>
      <link>https://Palaniappan12345.github.io/mlnotes/python/pandas/pandas-merging-joining/</link>
      <pubDate>Fri, 04 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://Palaniappan12345.github.io/mlnotes/python/pandas/pandas-merging-joining/</guid>
      <description>import numpy as np import scipy.stats import pandas as pd import sklearnleft = pd.DataFrame({ &amp;#39;id&amp;#39;:[1,2,3,4,5], &amp;#39;Name&amp;#39;: [&amp;#39;Alex&amp;#39;, &amp;#39;Amy&amp;#39;, &amp;#39;Allen&amp;#39;, &amp;#39;Alice&amp;#39;, &amp;#39;Ayoung&amp;#39;], &amp;#39;subject_id&amp;#39;:[&amp;#39;sub1&amp;#39;,&amp;#39;sub2&amp;#39;,&amp;#39;sub4&amp;#39;,&amp;#39;sub6&amp;#39;,&amp;#39;sub5&amp;#39;]}) right = pd.DataFrame( {&amp;#39;id&amp;#39;:[1,2,3,4,5], &amp;#39;Name&amp;#39;: [&amp;#39;Billy&amp;#39;, &amp;#39;Brian&amp;#39;, &amp;#39;Bran&amp;#39;, &amp;#39;Bryce&amp;#39;, &amp;#39;Betty&amp;#39;], &amp;#39;subject_id&amp;#39;:[&amp;#39;sub2&amp;#39;,&amp;#39;sub4&amp;#39;,&amp;#39;sub3&amp;#39;,&amp;#39;sub6&amp;#39;,&amp;#39;sub5&amp;#39;]}) left  .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }    id Name subject_id     0 1 Alex sub1   1 2 Amy sub2   2 3 Allen sub4   3 4 Alice sub6   4 5 Ayoung sub5     right  .</description>
    </item>
    
    <item>
      <title>Pandas-Missing-Data</title>
      <link>https://Palaniappan12345.github.io/mlnotes/python/pandas/pandas-missing-data/</link>
      <pubDate>Fri, 04 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://Palaniappan12345.github.io/mlnotes/python/pandas/pandas-missing-data/</guid>
      <description>import numpy as np import scipy.stats import pandas as pd import sklearndf = pd.DataFrame(np.random.randn(5, 3), index=[&amp;#39;a&amp;#39;, &amp;#39;c&amp;#39;, &amp;#39;e&amp;#39;, &amp;#39;f&amp;#39;, &amp;#39;h&amp;#39;],columns=[&amp;#39;one&amp;#39;, &amp;#39;two&amp;#39;, &amp;#39;three&amp;#39;]) df = df.reindex([&amp;#39;a&amp;#39;, &amp;#39;b&amp;#39;, &amp;#39;c&amp;#39;, &amp;#39;d&amp;#39;, &amp;#39;e&amp;#39;, &amp;#39;f&amp;#39;, &amp;#39;g&amp;#39;, &amp;#39;h&amp;#39;]) df  .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }    one two three     a -1.594997 -0.870257 -0.</description>
    </item>
    
    <item>
      <title>Pandas-Series</title>
      <link>https://Palaniappan12345.github.io/mlnotes/python/pandas/pandas-series/</link>
      <pubDate>Fri, 04 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://Palaniappan12345.github.io/mlnotes/python/pandas/pandas-series/</guid>
      <description>import numpy as np import scipy.stats import pandas as pd import sklearn#Creating empty series #import the pandas library and aliasing as pd import pandas as pd s = pd.Series() s &amp;lt;ipython-input-4-4eaadbf67d2e&amp;gt;:4: DeprecationWarning: The default dtype for empty Series will be &#39;object&#39; instead of &#39;float64&#39; in a future version. Specify a dtype explicitly to silence this warning. s = pd.Series() Series([], dtype: float64)  #Create a Series from ndarray data = np.</description>
    </item>
    
    <item>
      <title>Pandas-Sorting</title>
      <link>https://Palaniappan12345.github.io/mlnotes/python/pandas/pandas-sorting/</link>
      <pubDate>Fri, 04 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://Palaniappan12345.github.io/mlnotes/python/pandas/pandas-sorting/</guid>
      <description>import numpy as np import scipy.stats import pandas as pd import sklearnunsorted_df=pd.DataFrame(np.random.randn(10,2),index=[1,4,6,2,3,5,9,8,0,7],columns=[&amp;#39;col2&amp;#39;,&amp;#39;col1&amp;#39;]) (unsorted_df)  .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }    col2 col1     1 -0.219984 -0.464369   4 -1.300591 -0.076174   6 0.840346 -1.347094   2 0.221474 0.442064   3 -0.017141 -0.480142   5 -0.</description>
    </item>
    
    <item>
      <title>Percentiles-Metrics</title>
      <link>https://Palaniappan12345.github.io/mlnotes/python/numpy/percentiles_metrics/</link>
      <pubDate>Fri, 04 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://Palaniappan12345.github.io/mlnotes/python/numpy/percentiles_metrics/</guid>
      <description>import math import statistics import numpy as np import scipy.stats import pandas as pdx = [8.0, 1, 2.5, 4, 28.0] x_with_nan = [8.0, 1, 2.5, math.nan, 4, 28.0] x [8.0, 1, 2.5, 4, 28.0]  y, y_with_nan = np.array(x), np.array(x_with_nan) z, z_with_nan = pd.Series(x), pd.Series(x_with_nan) y array([ 8. , 1. , 2.5, 4. , 28. ])  x = [-5.0, -1.1, 0.1, 2.0, 8.0, 12.8, 21.0, 25.8, 41.0] statistics.quantiles(x, n=2) [8.</description>
    </item>
    
    <item>
      <title>Pie-chart</title>
      <link>https://Palaniappan12345.github.io/mlnotes/python/data_visualisation/pie_chart/</link>
      <pubDate>Fri, 04 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://Palaniappan12345.github.io/mlnotes/python/data_visualisation/pie_chart/</guid>
      <description>import math import statistics import numpy as np import scipy.stats import pandas as pdimport matplotlib.pyplot as plt plt.style.use(&amp;#39;ggplot&amp;#39;)fig, ax = plt.subplots() ax.pie((x, y, z), labels=(&amp;#39;x&amp;#39;, &amp;#39;y&amp;#39;, &amp;#39;z&amp;#39;), autopct=&amp;#39;%1.1f%%&amp;#39;) plt.show() </description>
    </item>
    
    <item>
      <title>Ranges(Min/Max)-Metrics</title>
      <link>https://Palaniappan12345.github.io/mlnotes/python/numpy/ranges_metrics/</link>
      <pubDate>Fri, 04 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://Palaniappan12345.github.io/mlnotes/python/numpy/ranges_metrics/</guid>
      <description>import math import statistics import numpy as np import scipy.stats import pandas as pdx = [8.0, 1, 2.5, 4, 28.0] x_with_nan = [8.0, 1, 2.5, math.nan, 4, 28.0] x [8.0, 1, 2.5, 4, 28.0]  y, y_with_nan = np.array(x), np.array(x_with_nan) z, z_with_nan = pd.Series(x), pd.Series(x_with_nan) y array([ 8. , 1. , 2.5, 4. , 28. ])  np.ptp(y) 27.0  np.ptp(y_with_nan) nan  np.amax(y) - np.amin(y) 27.0  np.nanmax(y_with_nan) - np.</description>
    </item>
    
    <item>
      <title>Skewness-Metrics</title>
      <link>https://Palaniappan12345.github.io/mlnotes/python/numpy/skewness_metrics/</link>
      <pubDate>Fri, 04 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://Palaniappan12345.github.io/mlnotes/python/numpy/skewness_metrics/</guid>
      <description>import math import statistics import numpy as np import scipy.stats import pandas as pdx = [8.0, 1, 2.5, 4, 28.0] x_with_nan = [8.0, 1, 2.5, math.nan, 4, 28.0] x [8.0, 1, 2.5, 4, 28.0]  y, y_with_nan = np.array(x), np.array(x_with_nan) z, z_with_nan = pd.Series(x), pd.Series(x_with_nan) y array([ 8. , 1. , 2.5, 4. , 28. ])  x = [8.0, 1, 2.5, 4, 28.0] n = len(x) mean_ = sum(x) / n var_ = sum((item - mean_)**2 for item in x) / (n - 1) std_ = var_ ** 0.</description>
    </item>
    
    <item>
      <title>Standard-Deviation-Metrics</title>
      <link>https://Palaniappan12345.github.io/mlnotes/python/numpy/standard_deviation_metrics/</link>
      <pubDate>Fri, 04 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://Palaniappan12345.github.io/mlnotes/python/numpy/standard_deviation_metrics/</guid>
      <description>import math import statistics import numpy as np import scipy.stats import pandas as pdx = [8.0, 1, 2.5, 4, 28.0] x_with_nan = [8.0, 1, 2.5, math.nan, 4, 28.0] x [8.0, 1, 2.5, 4, 28.0]  y, y_with_nan = np.array(x), np.array(x_with_nan) z, z_with_nan = pd.Series(x), pd.Series(x_with_nan) y array([ 8. , 1. , 2.5, 4. , 28. ])  n = len(x) mean_ = sum(x) / n var_ = sum((item - mean_)**2 for item in x) / (n - 1) var_ 123.</description>
    </item>
    
    <item>
      <title>Statistical-Function</title>
      <link>https://Palaniappan12345.github.io/mlnotes/python/pandas/statistical-function/</link>
      <pubDate>Fri, 04 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://Palaniappan12345.github.io/mlnotes/python/pandas/statistical-function/</guid>
      <description>import numpy as np import scipy.stats import pandas as pd import sklearns = pd.Series([1,2,3,4,5,4]) print (s.pct_change()) 0 NaN 1 1.000000 2 0.500000 3 0.333333 4 0.250000 5 -0.200000 dtype: float64  df = pd.DataFrame(np.random.randn(5, 2)) df.pct_change()  .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }    0 1     0 NaN NaN   1 -0.</description>
    </item>
    
    <item>
      <title>Streamplot</title>
      <link>https://Palaniappan12345.github.io/mlnotes/python/data_visualisation/streamplot/</link>
      <pubDate>Fri, 04 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://Palaniappan12345.github.io/mlnotes/python/data_visualisation/streamplot/</guid>
      <description>import numpy as np import matplotlib.pyplot as plt import matplotlib.gridspec as gridspecw = 3 Y, X = np.mgrid[-w:w:100j, -w:w:100j] U = -1 - X**2 + Y V = 1 + X - Y**2 speed = np.sqrt(U**2 + V**2) fig = plt.figure(figsize=(7, 9)) gs = gridspec.GridSpec(nrows=3, ncols=2, height_ratios=[1, 1, 2]) # Varying density along a streamline ax0 = fig.add_subplot(gs[0, 0]) ax0.streamplot(X, Y, U, V, density=[0.5, 1]) ax0.set_title(&amp;#39;Varying Density&amp;#39;) # Varying color along a streamline ax1 = fig.</description>
    </item>
    
    <item>
      <title>Train-Test-split(NB-Clasifier)</title>
      <link>https://Palaniappan12345.github.io/mlnotes/python/sklearn/train_test_split/</link>
      <pubDate>Fri, 04 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://Palaniappan12345.github.io/mlnotes/python/sklearn/train_test_split/</guid>
      <description>import math import statistics import numpy as np import scipy.stats import pandas as pd import sklearn from sklearn.naive_bayes import GaussianNB from sklearn.metrics import accuracy_score from sklearn.model_selection import train_test_splitdf = pd.read_csv(&amp;#39;glass.csv&amp;#39;)df  .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }    RI Na Mg Al Si K Ca Ba Fe Type     0 1.</description>
    </item>
    
    <item>
      <title>Variance-Metrics</title>
      <link>https://Palaniappan12345.github.io/mlnotes/python/numpy/variance_metrics/</link>
      <pubDate>Fri, 04 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://Palaniappan12345.github.io/mlnotes/python/numpy/variance_metrics/</guid>
      <description>import math import statistics import numpy as np import scipy.stats import pandas as pdx = [8.0, 1, 2.5, 4, 28.0] x_with_nan = [8.0, 1, 2.5, math.nan, 4, 28.0] x [8.0, 1, 2.5, 4, 28.0]  y, y_with_nan = np.array(x), np.array(x_with_nan) z, z_with_nan = pd.Series(x), pd.Series(x_with_nan) y array([ 8. , 1. , 2.5, 4. , 28. ])  n = len(x) mean_ = sum(x) / n var_ = sum((item - mean_)**2 for item in x) / (n - 1) var_ 123.</description>
    </item>
    
    <item>
      <title>Weighted-Mean-Metrics</title>
      <link>https://Palaniappan12345.github.io/mlnotes/python/numpy/weighted_mean_metrics/</link>
      <pubDate>Fri, 04 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://Palaniappan12345.github.io/mlnotes/python/numpy/weighted_mean_metrics/</guid>
      <description>import math import statistics import numpy as np import scipy.stats import pandas as pdx = [8.0, 1, 2.5, 4, 28.0] x_with_nan = [8.0, 1, 2.5, math.nan, 4, 28.0] x [8.0, 1, 2.5, 4, 28.0]  y, y_with_nan = np.array(x), np.array(x_with_nan) z, z_with_nan = pd.Series(x), pd.Series(x_with_nan) y array([ 8. , 1. , 2.5, 4. , 28. ])  0.2 * 2 + 0.5 * 4 + 0.3 * 8 4.8  x = [8.</description>
    </item>
    
    <item>
      <title>Working-with-text-data</title>
      <link>https://Palaniappan12345.github.io/mlnotes/python/pandas/working-with-text-data/</link>
      <pubDate>Fri, 04 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://Palaniappan12345.github.io/mlnotes/python/pandas/working-with-text-data/</guid>
      <description>import numpy as np import scipy.stats import pandas as pd import sklearns = pd.Series([&amp;#39;Tom&amp;#39;, &amp;#39;William Rick&amp;#39;, &amp;#39;John&amp;#39;, &amp;#39;Alber@t&amp;#39;, np.nan, &amp;#39;1234&amp;#39;,&amp;#39;SteveSmith&amp;#39;]) s 0 Tom 1 William Rick 2 John 3 Alber@t 4 NaN 5 1234 6 SteveSmith dtype: object  s = pd.Series([&amp;#39;Tom&amp;#39;, &amp;#39;William Rick&amp;#39;, &amp;#39;John&amp;#39;, &amp;#39;Alber@t&amp;#39;, np.nan, &amp;#39;1234&amp;#39;,&amp;#39;SteveSmith&amp;#39;]) s.str.lower() 0 tom 1 william rick 2 john 3 alber@t 4 NaN 5 1234 6 stevesmith dtype: object  s = pd.Series([&amp;#39;Tom&amp;#39;, &amp;#39;William Rick&amp;#39;, &amp;#39;John&amp;#39;, &amp;#39;Alber@t&amp;#39;, np.</description>
    </item>
    
    <item>
      <title>X-Y Plot</title>
      <link>https://Palaniappan12345.github.io/mlnotes/python/data_visualisation/x-y_plot/</link>
      <pubDate>Fri, 04 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://Palaniappan12345.github.io/mlnotes/python/data_visualisation/x-y_plot/</guid>
      <description>import math import statistics import numpy as np import scipy.stats import pandas as pdimport matplotlib.pyplot as plt plt.style.use(&amp;#39;ggplot&amp;#39;)x = np.arange(21) y = 5 + 2 * x + 2 * np.random.randn(21) slope, intercept, r, *__ = scipy.stats.linregress(x, y) line = f&amp;#39;Regression line: y={intercept:.2f}+{slope:.2f}x, r={r:.2f}&amp;#39;fig, ax = plt.subplots() ax.plot(x, y, linewidth=0, marker=&amp;#39;s&amp;#39;, label=&amp;#39;Data points&amp;#39;) ax.plot(x, intercept + slope * x, label=line) ax.set_xlabel(&amp;#39;x&amp;#39;) ax.set_ylabel(&amp;#39;y&amp;#39;) ax.legend(facecolor=&amp;#39;white&amp;#39;) plt.show() </description>
    </item>
    
    <item>
      <title>Pandas_basic</title>
      <link>https://Palaniappan12345.github.io/mlnotes/python/pandas/pandas_basic/</link>
      <pubDate>Tue, 11 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://Palaniappan12345.github.io/mlnotes/python/pandas/pandas_basic/</guid>
      <description>import pandas as pddf = pd.read_csv(&amp;#39;glass.csv&amp;#39;)df  .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }    RI Na Mg Al Si K Ca Ba Fe Type     0 1.52101 13.64 4.49 1.10 71.78 0.06 8.75 0.00 0.0 1   1 1.51761 13.89 3.60 1.36 72.73 0.48 7.83 0.00 0.0 1   2 1.</description>
    </item>
    
    <item>
      <title>Python_append</title>
      <link>https://Palaniappan12345.github.io/mlnotes/python/basics/python_append/</link>
      <pubDate>Tue, 11 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://Palaniappan12345.github.io/mlnotes/python/basics/python_append/</guid>
      <description>a=[1, 2, 3, 4]a.append(45)a [1, 2, 3, 4, 45]  </description>
    </item>
    
    <item>
      <title>Simple Python</title>
      <link>https://Palaniappan12345.github.io/mlnotes/python/basics/simple-python/</link>
      <pubDate>Sat, 20 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://Palaniappan12345.github.io/mlnotes/python/basics/simple-python/</guid>
      <description>print(&amp;#39;Hello Toronto&amp;#39;) Hello Toronto  print(2) 2  </description>
    </item>
    
    <item>
      <title>Template</title>
      <link>https://Palaniappan12345.github.io/mlnotes/python/basics/template/</link>
      <pubDate>Sat, 20 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://Palaniappan12345.github.io/mlnotes/python/basics/template/</guid>
      <description>print(&amp;#39;Hello Toronto&amp;#39;) Hello Toronto  print(2) 2  </description>
    </item>
    
  </channel>
</rss>